from langchain_community.document_loaders import WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_ollama import ChatOllama
from typing import List, Dict
from langchain_community.document_transformers import Html2TextTransformer
from langchain_core.prompts import ChatPromptTemplate


# Configuration
FORMATION_URLS = [
    "https://www.octo.academy/catalogue/formation/ddd01-ddd-domain-driven-design/",
    "https://www.octo.academy/catalogue/formation/ajava-developper-son-api-avec-java/",
    "https://www.octo.academy/catalogue/formation/az204-formation-azure-pour-les-developpeurs/",
]

# Initialisation des modÃ¨les
embeddings = OllamaEmbeddings(model="mistral")
llm = ChatOllama(model="mistral")

# Chargement des documents
loader = WebBaseLoader(FORMATION_URLS)
docs = loader.load()

# Transformation HTML en texte ciblÃ©
html_transformer = Html2TextTransformer()
cleaned_docs = html_transformer.transform_documents(
    docs,
    selectors=[
        "main",  # Cible la section principale
        "container",  # Cible la section principale
        "h1", "h2", "h3",  # Titres
        "#mainContent > section.details > div > div > div.subsection.public-cible"
    ]
)

# DÃ©coupage 
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,  
    chunk_overlap=200,
    separators=[
        "\n\n",
        "Objectifs",
        "Public cible", 
        "PrÃ©requis",
        "ModalitÃ©s pÃ©dagogiques"
    ]
)
splits = text_splitter.split_documents(cleaned_docs)

# CrÃ©ation de la base vectorielle
vectorstore = FAISS.from_documents(splits, embeddings)
retriever = vectorstore.as_retriever(
    search_kwargs={
        "k": 10,  # Augmenter le nombre de documents rÃ©cupÃ©rÃ©s
        "search_type": "similarity",
        "score_threshold": 0.4
    }
)

# DÃ©duplication des rÃ©sultats
def deduplicate_docs(docs: List) -> List:
    seen = set()
    unique = []
    for doc in docs:
        identifier = (doc.page_content, frozenset(doc.metadata.items()))
        if identifier not in seen:
            seen.add(identifier)
            unique.append(doc)
    return unique

# Ã‰valuation ciblÃ©e architecte
def evaluer_formations(profil: str) -> Dict:
    
    docs_pertinents = retriever.invoke(
        f"{profil} Public cible PrÃ©requis"  # Ajout des champs critiques
    )
    
    filtered_docs = [
        doc for doc in deduplicate_docs(docs_pertinents)
        if any(url in doc.metadata["source"] for url in FORMATION_URLS)
        and "public cible" in doc.page_content.lower()  # Attention Ã  la casse
        and profil.lower() in doc.page_content.lower()  # Filtrage direct
    ]

    
    # Restructuration du prompt
    context = "\n---\n".join(
        f"CONTENU DE LA FORMATION:\n{doc.page_content}\n"
        for doc in filtered_docs
    )

    prompt_template = ChatPromptTemplate.from_template("""
    Analysez EXCLUSIVEMENT ces sources pour le public '{profil}' :

    {context}

    Instructions strictes :
    1. Titre exact : Extraire le H1 ou le premier titre
    2. URL : Doit correspondre Ã  {allowed_urls}
    3. Public cible : Doit correspondre forcÃ©ment au public {profil}

    Formations interdites si :
    - L'URL ne correspond pas aux sources autorisÃ©es

    RÃ©ponse EXIGÃ‰E :
    "1. Titre exact: [titre]
    2. URL complÃ¨te: [url]
    3. Public cible: "[citation]""

    Si aucune correspondance : "Aucune formation adaptÃ©e"
    """)

        

    chain = prompt_template | llm
    allowed_urls = "\n- " + "\n- ".join(FORMATION_URLS)
    reponse = chain.invoke({
        "profil": profil,
        "context": context,
        "allowed_urls": allowed_urls
    })
    
    return {
        "analyse": reponse.content,
        "sources": list(set(doc.metadata["source"] for doc in filtered_docs))
    }

while True:  # Boucle d'interaction
    print("\nğŸ’¼ Veuillez dÃ©crire votre profil (ou 'q' pour quitter)")
    profil_utilisateur = input("> ")
    
    if profil_utilisateur.lower() == 'q':
        break
    
    if not profil_utilisateur.strip():
        print("âŒ Veuillez entrer une description valide")
        continue
    
    print("\nğŸ” Analyse en cours...")
    resultat = evaluer_formations(profil_utilisateur)


    print("\nğŸ† RÃ©sultats :")
    if "Aucune formation" not in resultat["analyse"]:
        for line in resultat["analyse"].split("\n"):
            if "http" in line:
                print(f"\nğŸ”— {line.strip()}")
            elif line.strip().startswith(("1.", "2.", "3.")):
                print(f"âœ… {line.strip()}")
    else:
        print("âŒ Aucune formation adaptÃ©e trouvÃ©e")

